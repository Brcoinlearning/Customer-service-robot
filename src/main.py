import os
import sys

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from parser.dsl_parser import DSLParser
from interpreter.interpreter import DSLInterpreter
from llm.spark_client import SparkLLMClient
from config.settings import Config
from core.enhanced_context import EnhancedConversationContext
from knowledge.product_knowledge import ProductKnowledge
from knowledge.dining_knowledge import DiningKnowledgeProvider

def load_dsl_script(file_path: str) -> str:
    """åŠ è½½DSLè„šæœ¬æ–‡ä»¶"""
    try:
        script_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        full_path = os.path.join(script_dir, file_path)
        print(f"å°è¯•åŠ è½½DSLè„šæœ¬: {full_path}")
        
        with open(full_path, 'r', encoding='utf-8') as f:
            content = f.read()
            print(f"DSLè„šæœ¬åŠ è½½æˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            return content
    except FileNotFoundError:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°DSLè„šæœ¬æ–‡ä»¶ {full_path}")
        return ""
    except Exception as e:
        print(f"åŠ è½½DSLè„šæœ¬æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return ""

def main():
    print("=" * 50)
    print("DSLå®¢æœæœºå™¨äººå¯åŠ¨ä¸­...")
    print("=" * 50)
    
    print("æ­¥éª¤1: é€‰æ‹©å¹¶åŠ è½½DSLè„šæœ¬...")
    print("å¯é€‰è„šæœ¬:")
    print("  1) ç”µå•†é¡¾é—® (ecommerce.dsl)")
    print("  2) é¤é¥®é¢„è®¢ (dining.dsl)")
    choice = input("è¯·è¾“å…¥åºå·é€‰æ‹©è„šæœ¬ï¼Œå›è½¦ä½¿ç”¨é»˜è®¤[1]: ").strip()
    if choice == "2":
        selected_script_path = "src/scripts/dining.dsl"
        selected_provider = "dining"
    else:
        selected_script_path = Config.DSL_SCRIPT_PATH
        selected_provider = "product"
    dsl_content = load_dsl_script(selected_script_path)
    if not dsl_content:
        print("âŒ DSLè„šæœ¬åŠ è½½å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        return
    print("âœ… DSLè„šæœ¬åŠ è½½æˆåŠŸ")
    
    # 2. è§£æDSL
    print("æ­¥éª¤2: æ­£åœ¨è§£æDSLè„šæœ¬...")
    parser = DSLParser()
    try:
        parsed_dsl = parser.parse(dsl_content)
        print(f"âœ… DSLè§£ææˆåŠŸ: æ‰¾åˆ° {len(parsed_dsl['intents'])} ä¸ªæ„å›¾, {len(parsed_dsl['rules'])} ä¸ªè§„åˆ™")
        
        print("è§£æåˆ°çš„æ„å›¾:")
        for intent_name, description in parsed_dsl['intents'].items():
            print(f"  - {intent_name}: {description}")
            
    except Exception as e:
        print(f"âŒ DSLè§£æé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 3. åˆå§‹åŒ–è§£é‡Šå™¨ã€ä¸Šä¸‹æ–‡ç®¡ç†å™¨å’ŒçŸ¥è¯†åº“
    print("æ­¥éª¤3: æ­£åœ¨åˆå§‹åŒ–è§£é‡Šå™¨...")
    try:
        interpreter = DSLInterpreter(parsed_dsl)
        context_manager = EnhancedConversationContext()
        context_manager.update_context("user_id", "current_user")
        if selected_provider == "dining":
            knowledge = DiningKnowledgeProvider()
        else:
            knowledge = ProductKnowledge()
        print("âœ… è§£é‡Šå™¨å’ŒçŸ¥è¯†åº“åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ è§£é‡Šå™¨æˆ–çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    # 4. åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ - ä½¿ç”¨é…ç½®ç±»
    print("æ­¥éª¤4: æ­£åœ¨åˆå§‹åŒ–LLMå®¢æˆ·ç«¯...")
    try:
        llm_client = SparkLLMClient(**Config.get_llm_config())  # ä½¿ç”¨é…ç½®ç±»
        print("âœ… LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    print("\n" + "=" * 50)
    print("ğŸ‰ DSLå®¢æœæœºå™¨äººå¯åŠ¨å®Œæˆï¼")
    print("å¯ç”¨æŒ‡ä»¤:")
    print("  - è¾“å…¥ä»»ä½•é—®é¢˜ä¸æœºå™¨äººå¯¹è¯")
    print("  - è¾“å…¥ 'exit' é€€å‡ºç¨‹åº")
    print("=" * 50)
    
    # 5. ä¸»å¾ªç¯
    while True:
        try:
            user_input = input("\nğŸ‘¤ ç”¨æˆ·: ").strip()
            
            if user_input.lower() == 'exit':
                print("å†è§ï¼")
                break
            
            if not user_input:
                continue
            
            # ä½¿ç”¨LLMè¯†åˆ«æ„å›¾ï¼ˆæºå¸¦å½“å‰ä¸Šä¸‹æ–‡æ‘˜è¦ï¼‰
            print("ğŸ¤– æ­£åœ¨åˆ†ææ„å›¾...", end="")
            context_for_llm = context_manager.get_context()
            detected_intent = llm_client.detect_intent(user_input, parsed_dsl['intents'], context_for_llm)
            print(f" [{detected_intent}]")

            # æ›´æ–°ä¸Šä¸‹æ–‡
            context_manager.update_context("current_intent", detected_intent)
            context_manager.add_message("user", user_input)

            # æ„é€ ä¼ ç»™è§£é‡Šå™¨çš„ä¸Šä¸‹æ–‡ï¼šåŒ…å«åŸå§‹ä¸Šä¸‹æ–‡ã€çŸ¥è¯†åº“å¼•ç”¨ã€ç®¡ç†å™¨å¼•ç”¨å’Œæœ¬è½®è¾“å…¥
            ctx = context_manager.get_context()
            ctx["_manager"] = context_manager
            ctx["user_input"] = user_input
            ctx["knowledge"] = knowledge

            # æ‰§è¡ŒDSLè§„åˆ™ - ä¼ é€’ä¸Šä¸‹æ–‡
            responses = interpreter.execute(detected_intent, ctx)

            # è¾“å‡ºå“åº”å¹¶æ›´æ–°ä¸Šä¸‹æ–‡
            print("ğŸ¤– å®¢æœ:", end="")
            for i, response in enumerate(responses):
                if i == 0:
                    print(f" {response}")
                else:
                    print(f"       {response}")
            
            # å°†æœºå™¨äººå“åº”æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
            for response in responses:
                context_manager.add_message("assistant", response)
                    
        except KeyboardInterrupt:
            print("\n\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
            break
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    main()