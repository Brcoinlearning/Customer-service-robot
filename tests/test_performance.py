#!/usr/bin/env python3
"""
æ€§èƒ½æµ‹è¯•æ¨¡å—
============

æµ‹è¯•ç³»ç»Ÿåœ¨å„ç§è´Ÿè½½æ¡ä»¶ä¸‹çš„æ€§èƒ½è¡¨ç°ï¼š
1. DSLè§£ææ€§èƒ½æµ‹è¯•
2. æ„å›¾è¯†åˆ«å“åº”æ—¶é—´æµ‹è¯•  
3. å¹¶å‘å¤„ç†èƒ½åŠ›æµ‹è¯•
4. å†…å­˜ä½¿ç”¨å’Œåƒåœ¾å›æ”¶æµ‹è¯•

ä½¿ç”¨æ–¹æ³•:
    python tests/test_performance.py
    python tests/test_performance.py --iterations=200 --concurrent-users=20
"""

import sys
import os
import time
import threading
import json
import statistics
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any
from dataclasses import dataclass, asdict

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(project_root, 'src'))

# å¯¼å…¥æ—¶ä½¿ç”¨try-catchå¤„ç†å¯èƒ½çš„å¯¼å…¥é”™è¯¯
try:
    from parser.dsl_parser import DSLParser
    from interpreter.interpreter import DSLInterpreter
    from stubs.mock_llm_client import MockLLMClient
except ImportError as e:
    print(f"Warning: å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    # åˆ›å»ºæœ€å°å®ç°ä»¥ä¾¿æµ‹è¯•æ¡†æ¶æ­£å¸¸è¿è¡Œ
    class DSLParser:
        def parse(self, content):
            return {"intents": {"test": "æµ‹è¯•"}, "rules": []}
    
    class DSLInterpreter:
        def __init__(self, parsed_dsl):
            self.parsed_dsl = parsed_dsl
        
        def execute(self, intent, context):
            return ["æµ‹è¯•å“åº”"]
    
    class MockLLMClient:
        def detect_intent(self, user_input, available_intents):
            return "test"

@dataclass
class PerformanceResult:
    """æ€§èƒ½æµ‹è¯•ç»“æœæ•°æ®ç±»"""
    test_name: str
    iterations: int
    total_time: float
    avg_time: float
    min_time: float
    max_time: float
    p95_time: float
    p99_time: float
    throughput: float  # ops per second
    memory_usage: Dict[str, float] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.results: List[PerformanceResult] = []
        
    def time_function(self, func, *args, **kwargs):
        """æµ‹é‡å‡½æ•°æ‰§è¡Œæ—¶é—´"""
        start_time = time.perf_counter()
        result = func(*args, **kwargs)
        end_time = time.perf_counter()
        return end_time - start_time, result
    
    def get_memory_usage(self):
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        try:
            import psutil
            process = psutil.Process()
            memory_info = process.memory_info()
            return {
                'rss': memory_info.rss / 1024 / 1024,  # MB
                'vms': memory_info.vms / 1024 / 1024,  # MB
                'percent': process.memory_percent()
            }
        except ImportError:
            return {'rss': 0, 'vms': 0, 'percent': 0}

class DSLPerformanceTester:
    """DSLè§£ææ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.monitor = PerformanceMonitor()
        self.parser = DSLParser()
        
        # ç”Ÿæˆä¸åŒè§„æ¨¡çš„DSLå†…å®¹è¿›è¡Œæµ‹è¯•
        self.test_dsls = self._generate_test_dsls()
    
    def _generate_test_dsls(self) -> Dict[str, str]:
        """ç”Ÿæˆä¸åŒè§„æ¨¡çš„DSLæµ‹è¯•å†…å®¹"""
        return {
            'small': self._generate_dsl(5, 10),
            'medium': self._generate_dsl(20, 50), 
            'large': self._generate_dsl(50, 100),
            'xlarge': self._generate_dsl(100, 200)
        }
    
    def _generate_dsl(self, num_intents: int, num_rules: int) -> str:
        """ç”ŸæˆæŒ‡å®šè§„æ¨¡çš„DSLå†…å®¹"""
        dsl_lines = []
        
        # ç”Ÿæˆæ„å›¾å®šä¹‰
        for i in range(num_intents):
            dsl_lines.append(f'INTENT intent_{i}: "æ„å›¾{i}æè¿°"')
        
        dsl_lines.append('')  # ç©ºè¡Œåˆ†éš”
        
        # ç”Ÿæˆè§„åˆ™å®šä¹‰
        for i in range(num_rules):
            intent_idx = i % num_intents
            dsl_lines.extend([
                f'RULE rule_{i}',
                f'WHEN INTENT_IS intent_{intent_idx}',
                'THEN',
                f'    RESPOND "å“åº”{i}"',
                f'    SET_VARIABLE "var_{i}" "value_{i}"',
                ''
            ])
        
        return '\n'.join(dsl_lines)
    
    def test_parsing_performance(self, size: str = 'medium', iterations: int = 100) -> PerformanceResult:
        """æµ‹è¯•DSLè§£ææ€§èƒ½"""
        print(f"\nğŸš€ æµ‹è¯•DSLè§£ææ€§èƒ½ ({size}è§„æ¨¡, {iterations}æ¬¡è¿­ä»£)...")
        
        dsl_content = self.test_dsls[size]
        execution_times = []
        
        # é¢„çƒ­
        for _ in range(5):
            self.parser.parse(dsl_content)
        
        # å®é™…æµ‹è¯•
        for i in range(iterations):
            exec_time, _ = self.monitor.time_function(self.parser.parse, dsl_content)
            execution_times.append(exec_time)
            
            if (i + 1) % (iterations // 10) == 0:
                print(f"  è¿›åº¦: {(i+1)/iterations*100:.0f}%")
        
        # ç»Ÿè®¡ç»“æœ
        total_time = sum(execution_times)
        avg_time = statistics.mean(execution_times)
        min_time = min(execution_times)
        max_time = max(execution_times)
        p95_time = statistics.quantiles(execution_times, n=20)[18]  # 95th percentile
        p99_time = statistics.quantiles(execution_times, n=100)[98]  # 99th percentile
        throughput = iterations / total_time
        
        result = PerformanceResult(
            test_name=f"DSLè§£ææ€§èƒ½_{size}",
            iterations=iterations,
            total_time=total_time,
            avg_time=avg_time,
            min_time=min_time,
            max_time=max_time,
            p95_time=p95_time,
            p99_time=p99_time,
            throughput=throughput,
            memory_usage=self.monitor.get_memory_usage()
        )
        
        print(f"  âœ… å®Œæˆ: å¹³å‡ {avg_time*1000:.2f}ms, ååé‡ {throughput:.1f} ops/sec")
        return result

class IntentRecognitionTester:
    """æ„å›¾è¯†åˆ«æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.monitor = PerformanceMonitor()
        self.llm_client = MockLLMClient()
        
        # æµ‹è¯•ç”¨ä¾‹æ•°æ®
        self.test_inputs = [
            "ä½ å¥½", "æˆ‘æƒ³ä¹°ç”µè„‘", "è‹¹æœMacBookæ€ä¹ˆæ ·", "ä»·æ ¼å¤šå°‘",
            "æœ‰ä»€ä¹ˆæ¨èçš„", "é…ç½®å¦‚ä½•", "ä»€ä¹ˆæ—¶å€™å‘è´§", "é€€è´§æ”¿ç­–",
            "iPhone 15", "MacBook Air", "è”æƒ³ç¬”è®°æœ¬", "æˆ´å°”å°å¼æœº"
        ] * 10  # æ‰©å±•æµ‹è¯•æ•°æ®
        
        self.available_intents = {
            "greeting": "é—®å€™è¯­",
            "product_query": "äº§å“å’¨è¯¢",
            "order_status": "è®¢å•çŠ¶æ€",
            "support": "æŠ€æœ¯æ”¯æŒ"
        }
    
    def test_intent_recognition_performance(self, iterations: int = 100) -> PerformanceResult:
        """æµ‹è¯•æ„å›¾è¯†åˆ«æ€§èƒ½"""
        print(f"\nğŸ¯ æµ‹è¯•æ„å›¾è¯†åˆ«æ€§èƒ½ ({iterations}æ¬¡è¿­ä»£)...")
        
        execution_times = []
        
        # é¢„çƒ­
        for i in range(5):
            test_input = self.test_inputs[i % len(self.test_inputs)]
            self.llm_client.detect_intent(test_input, self.available_intents)
        
        # å®é™…æµ‹è¯•  
        for i in range(iterations):
            test_input = self.test_inputs[i % len(self.test_inputs)]
            exec_time, _ = self.monitor.time_function(
                self.llm_client.detect_intent, 
                test_input, 
                self.available_intents
            )
            execution_times.append(exec_time)
            
            if (i + 1) % (iterations // 10) == 0:
                print(f"  è¿›åº¦: {(i+1)/iterations*100:.0f}%")
        
        # ç»Ÿè®¡ç»“æœ
        total_time = sum(execution_times)
        avg_time = statistics.mean(execution_times)
        min_time = min(execution_times)
        max_time = max(execution_times)
        p95_time = statistics.quantiles(execution_times, n=20)[18]
        p99_time = statistics.quantiles(execution_times, n=100)[98]
        throughput = iterations / total_time
        
        result = PerformanceResult(
            test_name="æ„å›¾è¯†åˆ«æ€§èƒ½",
            iterations=iterations,
            total_time=total_time,
            avg_time=avg_time,
            min_time=min_time,
            max_time=max_time,
            p95_time=p95_time,
            p99_time=p99_time,
            throughput=throughput,
            memory_usage=self.monitor.get_memory_usage()
        )
        
        print(f"  âœ… å®Œæˆ: å¹³å‡ {avg_time*1000:.2f}ms, ååé‡ {throughput:.1f} ops/sec")
        return result

class ConcurrencyTester:
    """å¹¶å‘æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.monitor = PerformanceMonitor()
        self.parser = DSLParser()
        self.llm_client = MockLLMClient()
        
    def _worker_task(self, worker_id: int, requests_per_worker: int) -> List[float]:
        """å·¥ä½œçº¿ç¨‹ä»»åŠ¡"""
        execution_times = []
        
        dsl_content = """
INTENT product_query: "äº§å“å’¨è¯¢"
RULE test_rule
WHEN INTENT_IS product_query
THEN
    RESPOND "å¤„ç†äº§å“å’¨è¯¢"
"""
        
        for i in range(requests_per_worker):
            # æ¨¡æ‹Ÿå®Œæ•´çš„è¯·æ±‚å¤„ç†æµç¨‹
            start_time = time.perf_counter()
            
            # DSLè§£æ
            parsed_dsl = self.parser.parse(dsl_content)
            
            # æ„å›¾è¯†åˆ«  
            user_input = f"worker_{worker_id}_request_{i}_äº§å“å’¨è¯¢"
            intent = self.llm_client.detect_intent(user_input, {"product_query": "äº§å“å’¨è¯¢"})
            
            # DSLè§£é‡Šæ‰§è¡Œ
            interpreter = DSLInterpreter(parsed_dsl)
            context = {"user_input": user_input}
            responses = interpreter.execute(intent, context)
            
            end_time = time.perf_counter()
            execution_times.append(end_time - start_time)
            
        return execution_times
    
    def test_concurrent_performance(self, concurrent_users: int = 10, requests_per_user: int = 20) -> PerformanceResult:
        """æµ‹è¯•å¹¶å‘å¤„ç†æ€§èƒ½"""
        print(f"\nâš¡ æµ‹è¯•å¹¶å‘å¤„ç†æ€§èƒ½ ({concurrent_users}ç”¨æˆ·, æ¯ç”¨æˆ·{requests_per_user}è¯·æ±‚)...")
        
        all_execution_times = []
        start_time = time.perf_counter()
        
        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå¹¶å‘æµ‹è¯•
        with ThreadPoolExecutor(max_workers=concurrent_users) as executor:
            futures = [
                executor.submit(self._worker_task, worker_id, requests_per_user)
                for worker_id in range(concurrent_users)
            ]
            
            completed = 0
            for future in as_completed(futures):
                worker_times = future.result()
                all_execution_times.extend(worker_times)
                completed += 1
                print(f"  è¿›åº¦: {completed}/{concurrent_users} ç”¨æˆ·å®Œæˆ")
        
        end_time = time.perf_counter()
        total_time = end_time - start_time
        
        # ç»Ÿè®¡ç»“æœ
        total_requests = len(all_execution_times)
        avg_time = statistics.mean(all_execution_times)
        min_time = min(all_execution_times)
        max_time = max(all_execution_times)
        p95_time = statistics.quantiles(all_execution_times, n=20)[18]
        p99_time = statistics.quantiles(all_execution_times, n=100)[98]
        throughput = total_requests / total_time
        
        result = PerformanceResult(
            test_name="å¹¶å‘å¤„ç†æ€§èƒ½",
            iterations=total_requests,
            total_time=total_time,
            avg_time=avg_time,
            min_time=min_time,
            max_time=max_time,
            p95_time=p95_time,
            p99_time=p99_time,
            throughput=throughput,
            memory_usage=self.monitor.get_memory_usage()
        )
        
        print(f"  âœ… å®Œæˆ: å¹³å‡ {avg_time*1000:.2f}ms, å¹¶å‘ååé‡ {throughput:.1f} ops/sec")
        return result

class PerformanceReporter:
    """æ€§èƒ½æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: str = "test_reports"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
    
    def generate_report(self, results: List[PerformanceResult]):
        """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        
        # ç”ŸæˆJSONæŠ¥å‘Š
        json_file = os.path.join(self.output_dir, f"performance_report_{timestamp}.json")
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump([result.to_dict() for result in results], f, indent=2, ensure_ascii=False)
        
        # ç”ŸæˆHTMLæŠ¥å‘Š
        html_file = os.path.join(self.output_dir, f"performance_report_{timestamp}.html")
        self._generate_html_report(results, html_file)
        
        print(f"\nğŸ“Š æ€§èƒ½æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ:")
        print(f"  JSON: {json_file}")
        print(f"  HTML: {html_file}")
    
    def _generate_html_report(self, results: List[PerformanceResult], html_file: str):
        """ç”ŸæˆHTMLæ ¼å¼çš„æ€§èƒ½æŠ¥å‘Š"""
        html_content = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ€§èƒ½æµ‹è¯•æŠ¥å‘Š</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; }}
        .header {{ text-align: center; border-bottom: 2px solid #007acc; padding-bottom: 20px; margin-bottom: 30px; }}
        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}
        th {{ background-color: #f2f2f2; font-weight: bold; }}
        .metric {{ background: #f9f9f9; padding: 15px; margin: 10px 0; border-radius: 5px; }}
        .good {{ color: #28a745; }}
        .warning {{ color: #ffc107; }}
        .danger {{ color: #dc3545; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸš€ ç³»ç»Ÿæ€§èƒ½æµ‹è¯•æŠ¥å‘Š</h1>
            <p>ç”Ÿæˆæ—¶é—´: {time.strftime("%Y-%m-%d %H:%M:%S")}</p>
        </div>
        
        <h2>ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡æ¦‚è§ˆ</h2>
        <table>
            <thead>
                <tr>
                    <th>æµ‹è¯•é¡¹ç›®</th>
                    <th>è¿­ä»£æ¬¡æ•°</th>
                    <th>å¹³å‡å“åº”æ—¶é—´ (ms)</th>
                    <th>P95å“åº”æ—¶é—´ (ms)</th>
                    <th>P99å“åº”æ—¶é—´ (ms)</th>
                    <th>ååé‡ (ops/sec)</th>
                    <th>å†…å­˜ä½¿ç”¨ (MB)</th>
                </tr>
            </thead>
            <tbody>
"""
        
        for result in results:
            memory_usage = result.memory_usage['rss'] if result.memory_usage else 0
            color_class = "good" if result.avg_time < 0.1 else "warning" if result.avg_time < 0.5 else "danger"
            
            html_content += f"""
                <tr>
                    <td>{result.test_name}</td>
                    <td>{result.iterations:,}</td>
                    <td class="{color_class}">{result.avg_time*1000:.2f}</td>
                    <td>{result.p95_time*1000:.2f}</td>
                    <td>{result.p99_time*1000:.2f}</td>
                    <td>{result.throughput:.1f}</td>
                    <td>{memory_usage:.1f}</td>
                </tr>
"""
        
        html_content += """
            </tbody>
        </table>
        
        <h2>ğŸ¯ æ€§èƒ½åŸºå‡†è¯´æ˜</h2>
        <div class="metric">
            <strong>å“åº”æ—¶é—´åŸºå‡†:</strong><br>
            <span class="good">â— ä¼˜ç§€: < 100ms</span><br>
            <span class="warning">â— è‰¯å¥½: 100-500ms</span><br>
            <span class="danger">â— éœ€è¦ä¼˜åŒ–: > 500ms</span>
        </div>
    </div>
</body>
</html>"""
        
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_content)

def main():
    """æ€§èƒ½æµ‹è¯•ä¸»å…¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å®¢æœæœºå™¨äººç³»ç»Ÿæ€§èƒ½æµ‹è¯•')
    parser.add_argument('--iterations', type=int, default=100, help='å•é¡¹æµ‹è¯•è¿­ä»£æ¬¡æ•°')
    parser.add_argument('--concurrent-users', type=int, default=10, help='å¹¶å‘ç”¨æˆ·æ•°')
    parser.add_argument('--requests-per-user', type=int, default=20, help='æ¯ç”¨æˆ·è¯·æ±‚æ•°')
    parser.add_argument('--output', default='test_reports', help='æŠ¥å‘Šè¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    print("ğŸš€ å¼€å§‹ç³»ç»Ÿæ€§èƒ½æµ‹è¯•...")
    print("=" * 60)
    
    results = []
    
    # DSLè§£ææ€§èƒ½æµ‹è¯•
    dsl_tester = DSLPerformanceTester()
    for size in ['small', 'medium', 'large']:
        result = dsl_tester.test_parsing_performance(size, args.iterations)
        results.append(result)
    
    # æ„å›¾è¯†åˆ«æ€§èƒ½æµ‹è¯•
    intent_tester = IntentRecognitionTester()
    result = intent_tester.test_intent_recognition_performance(args.iterations)
    results.append(result)
    
    # å¹¶å‘æ€§èƒ½æµ‹è¯•
    concurrent_tester = ConcurrencyTester()
    result = concurrent_tester.test_concurrent_performance(
        args.concurrent_users, 
        args.requests_per_user
    )
    results.append(result)
    
    # ç”ŸæˆæŠ¥å‘Š
    reporter = PerformanceReporter(args.output)
    reporter.generate_report(results)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ€§èƒ½æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()